{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30787,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/hatemamine/fine-tuning-crossencoder-using-knowledge-distilati?scriptVersionId=222419582\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"https://huggingface.co/unicamp-dl/mMiniLM-L6-v2-mmarco-v2\nhttps://huggingface.co/aubmindlab/araelectra-base-discriminator","metadata":{}},{"cell_type":"markdown","source":"%env PATH=/usr/local/cuda/bin:/opt/conda/bin:/opt/conda/condabin:/opt/conda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\n!pip install huggingface_hub -q\n!pip install datasets -q\n!pip install torch -q\n!pip install transformers -q\n!pip install tensorflow-cpu==2.16.1 -q\n!pip install tf-keras==2.16.0 --no-dependencies -q\n!pip install wandb -q\n!pip install -U accelerate -q\n!pip install -U transformers[torch] -q\n!pip install sentence_transformers -q","metadata":{}},{"cell_type":"code","source":"organization_dataset_id=\"hatemestinbejaia/ExperimentDATA_knowledge_distillation_vs_fine_tuning\"\ndev_name= \"dev_samples_araelectra.pkl\"\n#model =\"AraELECTRA\"\n#model =\"AraDPR\"\n#model =\"mMiniLML12v2\"\n# fine-tuning using knowledge distilation\n#model =\"KDAraELECTRA\"\nmodel =\"KDAraDPR\"\n#model =\"KDmMiniLML12v2\"\nif model ==\"KDAraELECTRA\" :\n    args_model=\"aubmindlab/araelectra-base-discriminator\"\n    dataset_name= \"KDtrain5Mx2tokenizedAraELECTRA\"\n    checkpoint = \"hatemestinbejaia/mmarco-Arabic-AraElectra-cross-encoder-KD-v1\"\nif model ==\"AraELECTRA\" :\n    args_model=\"aubmindlab/araelectra-base-discriminator\"\n    dataset_name= \"train5Mx2tokenized\"+model\n    checkpoint = \"hatemestinbejaia/mmarco-Arabic-AraElectra-cross-encoder-NoKD-v1\"\nif model ==\"AraDPR\" :\n    args_model=\"abdoelsayed/AraDPR\"\n    dataset_name= \"train5Mx2tokenized\"+model\n    checkpoint = \"hatemestinbejaia/mmarco-Arabic-AraDPR-cross-encoder-NoKD-v1\"\nif model ==\"KDAraDPR\" :\n    args_model=\"abdoelsayed/AraDPR\"\n    dataset_name= \"KDtrain5Mx2tokenizedAraDPR\"\n    checkpoint = \"hatemestinbejaia/mmarco-Arabic-AraDPR-cross-encoder-KD-v1\"\nif model ==\"mMiniLML12v2\" :\n    args_model=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n    dataset_name= \"train5Mx2tokenized\"+model\n    checkpoint = \"hatemestinbejaia/mmarco-Arabic-mMiniLML-cross-encoder-NoKD-v1\"\nif model ==\"KDmMiniLML12v2\" :\n    args_model=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n    dataset_name= \"KDtrain5Mx2tokenizedmMiniLML12v2\"\n    checkpoint = \"hatemestinbejaia/mmarco-Arabic-mMiniLML-cross-encoder-KD-v1\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T20:16:58.2656Z","iopub.execute_input":"2025-02-13T20:16:58.266047Z","iopub.status.idle":"2025-02-13T20:16:58.272923Z","shell.execute_reply.started":"2025-02-13T20:16:58.266012Z","shell.execute_reply":"2025-02-13T20:16:58.27144Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"!pip install sentence_transformers -q\n!pip install huggingface_hub -q\n!pip install wandb -q","metadata":{"execution":{"iopub.status.busy":"2025-02-13T20:26:26.473732Z","iopub.execute_input":"2025-02-13T20:26:26.474027Z","iopub.status.idle":"2025-02-13T20:26:36.624453Z","shell.execute_reply.started":"2025-02-13T20:26:26.474004Z","shell.execute_reply":"2025-02-13T20:26:36.623401Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.19.1)\nRequirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\nRequirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\nRequirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.3.6)\nRequirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\nRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\nRequirement already satisfied: pydantic<3,>=2.6 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.11.0a1)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.2)\nRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.32.3)\nRequirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.19.2)\nRequirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.4)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (75.1.0)\nRequirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.12.2)\nRequirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2.6->wandb) (0.7.0)\nRequirement already satisfied: pydantic-core==2.28.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2.6->wandb) (2.28.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2025.1.31)\nRequirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"#get the train dataset\nfrom datasets import load_from_disk, load_dataset\ntrain_dataset = load_dataset(organization_dataset_id, dataset_name, trust_remote_code=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T20:17:33.543716Z","iopub.execute_input":"2025-02-13T20:17:33.544036Z","iopub.status.idle":"2025-02-13T20:19:30.704196Z","shell.execute_reply.started":"2025-02-13T20:17:33.54401Z","shell.execute_reply":"2025-02-13T20:19:30.703307Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/27.2k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a640f5d7cc10463f93c19c13fe1fa027"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Resolving data files:   0%|          | 0/32 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af3eaae09963440c9b2ffc0eb35af984"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0/32 [00:00<?, ?files/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb3209005b4346c88a668b1d77815414"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train0-00000-of-00032.parquet:   0%|          | 0.00/54.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8084de6b0937455f87804c41823396ed"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train0-00001-of-00032.parquet:   0%|          | 0.00/52.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e2752245b1d347638599e88ca3f15e7d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train0-00002-of-00032.parquet:   0%|          | 0.00/54.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"066dd6253f584b7f834b77afc4fbe5ff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train0-00003-of-00032.parquet:   0%|          | 0.00/55.6M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b9a72d9108f4118ae1745451770d0cd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train0-00004-of-00032.parquet:   0%|          | 0.00/53.8M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e645eda1bcf44b2399be0d1d3e98e569"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train0-00005-of-00032.parquet:   0%|          | 0.00/54.0M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb5e9877e0134e72b2ea03584c779fd6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train0-00006-of-00032.parquet:   0%|          | 0.00/53.0M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"26772e67a5364c59b8bb8d7c38fbd94b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train0-00007-of-00032.parquet:   0%|          | 0.00/54.7M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eff3a586628845ab8fb41aa32ea2488d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train0-00008-of-00032.parquet:   0%|          | 0.00/53.0M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d197d29f9b2640489f4dcc8adb269f79"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train0-00009-of-00032.parquet:   0%|          | 0.00/54.0M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b53fa4b493e48aa9919dc923c1c9f04"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train0-00010-of-00032.parquet:   0%|          | 0.00/54.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b5a4800327a34c4ea6d1d9fca287435f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train0-00011-of-00032.parquet:   0%|          | 0.00/53.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d9c08cabc9314809858182896193d149"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train0-00012-of-00032.parquet:   0%|          | 0.00/54.0M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bdb018c621074ef29b56781fcbdd544a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train0-00013-of-00032.parquet:   0%|          | 0.00/53.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c4b0c4381233465abdaa3a1e06a1bb6b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train0-00014-of-00032.parquet:   0%|          | 0.00/53.6M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3aa836599e8f40bba6d6118135b26e30"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train0-00015-of-00032.parquet:   0%|          | 0.00/54.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c59bb001f7784eab8aec2b3ab149c51c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train0-00016-of-00032.parquet:   0%|          | 0.00/53.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b3194fd9be3469bb3d69119a9e1031e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train0-00017-of-00032.parquet:   0%|          | 0.00/53.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c5c67715bb649ac8c6181f342a8ca54"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train0-00018-of-00032.parquet:   0%|          | 0.00/53.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d7a4263d8a84413b7e3d80d8d2b3330"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train0-00019-of-00032.parquet:   0%|          | 0.00/52.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"10ce40eb2347462da02dc8b8270d5063"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train0-00020-of-00032.parquet:   0%|          | 0.00/53.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6222035bffb740fdaa538201b4e48034"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train0-00021-of-00032.parquet:   0%|          | 0.00/54.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"90694ace34524b4da9d1733927827077"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train0-00022-of-00032.parquet:   0%|          | 0.00/54.6M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f403bb2240c476ba980a721c63171b3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train0-00023-of-00032.parquet:   0%|          | 0.00/53.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"936193cfdd0441169a297a5674875366"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train0-00024-of-00032.parquet:   0%|          | 0.00/53.7M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f3e6e1d10c8e49fca15cc17e73907ba3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train0-00025-of-00032.parquet:   0%|          | 0.00/54.3M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d2da572637934fd3930ee61240fd54a2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train0-00026-of-00032.parquet:   0%|          | 0.00/52.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9459c0c57697473ea26b0e483664d47a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train0-00027-of-00032.parquet:   0%|          | 0.00/53.0M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2806bb0648e545c29aa41251262f31f5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train0-00028-of-00032.parquet:   0%|          | 0.00/52.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f416332ce7f4472bce80c67759d7e27"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train0-00029-of-00032.parquet:   0%|          | 0.00/53.7M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a7ce016d0eb94bd4bef7517917b03cc6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train0-00030-of-00032.parquet:   0%|          | 0.00/54.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e0ed75896bf5400ca95e614aef284a9b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train0-00031-of-00032.parquet:   0%|          | 0.00/53.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a48c0d75d6544f7bd5d4e996d43827e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00000-of-00001.parquet:   0%|          | 0.00/3.39M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25e142b5ca6c48dbb4cb7fa5a4f24d1b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train0 split:   0%|          | 0/10000000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d829ed99b6d4437cb7c9a82e1f4855df"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/20000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e466f63845474a7a9a9dfbfc9e3d90eb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading dataset shards:   0%|          | 0/32 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c08bec7839204899b2be5568b0d9dda2"}},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"train_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T20:20:20.257811Z","iopub.execute_input":"2025-02-13T20:20:20.258341Z","iopub.status.idle":"2025-02-13T20:20:20.263697Z","shell.execute_reply.started":"2025-02-13T20:20:20.258295Z","shell.execute_reply":"2025-02-13T20:20:20.263088Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train0: Dataset({\n        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n        num_rows: 10000000\n    })\n    test: Dataset({\n        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n        num_rows: 20000\n    })\n})"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"import torch\nfrom datasets import load_dataset\nfrom datetime import datetime\nfrom transformers import (\n    Trainer,\n    AutoModelForSequenceClassification,\n    AutoTokenizer,\n    AutoConfig,\n    TrainingArguments,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T20:20:30.99878Z","iopub.execute_input":"2025-02-13T20:20:30.999066Z","iopub.status.idle":"2025-02-13T20:20:52.01467Z","shell.execute_reply.started":"2025-02-13T20:20:30.999045Z","shell.execute_reply":"2025-02-13T20:20:52.013889Z"}},"outputs":[{"name":"stderr","text":"The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d989ddc9003648b7b98074b92407fd4b"}},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModel\nprint(args_model)\ntokenizer  = AutoTokenizer.from_pretrained(args_model)\nconfig = AutoConfig.from_pretrained(args_model)\nconfig.num_labels = 1\nconfig.problem_type = \"multi_label_classification\"\nmodel = AutoModelForSequenceClassification.from_pretrained(args_model, config=config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T20:21:01.482376Z","iopub.execute_input":"2025-02-13T20:21:01.483079Z","iopub.status.idle":"2025-02-13T20:21:21.859647Z","shell.execute_reply.started":"2025-02-13T20:21:01.483046Z","shell.execute_reply":"2025-02-13T20:21:21.858536Z"}},"outputs":[{"name":"stdout","text":"abdoelsayed/AraDPR\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5236806d59114582b1aafb3f78c96090"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/658 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"524af265b674471babb39f15e7fabbc4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"44b4934902614e718aae10bd5c2997b2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"761af509d2e8498ab72797832b5bca5d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/711M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f6f0ccc58ed9497295961515647f3706"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at abdoelsayed/AraDPR and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# to use wandb uncomment and change report_to = 'wandb' in TrainingArguments\n\"\"\"\nimport wandb\nimport os\nos.environ[\"WANDB_API_KEY\"] = \"your wandb api key\"\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T20:25:18.537273Z","iopub.execute_input":"2025-02-13T20:25:18.537627Z","iopub.status.idle":"2025-02-13T20:25:18.542381Z","shell.execute_reply.started":"2025-02-13T20:25:18.5376Z","shell.execute_reply":"2025-02-13T20:25:18.54167Z"}},"outputs":[{"name":"stdout","text":"cuda:0\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\nprint(device)\neval_steps =2000\nfrom transformers import EarlyStoppingCallback, IntervalStrategy\ntraining_args = TrainingArguments(\n        f\"training_with_callbacks\",\n        evaluation_strategy = IntervalStrategy.STEPS, # \"steps\"\n        eval_steps = eval_steps, # Evaluation and Save happens every 50 steps\n        save_total_limit = 2,\n        save_steps= eval_steps,\n        fp16=True,\n        fp16_backend=\"amp\",\n        per_device_train_batch_size=128, \n        #gradient_accumulation_steps=4,\n        logging_steps=eval_steps,\n        warmup_ratio=0.07,\n        num_train_epochs=3, \n        learning_rate = 7e-6,\n        weight_decay= 0.0,\n        metric_for_best_model = 'MRR@10',\n        greater_is_better=True,\n       load_best_model_at_end=True,\n       report_to = None,             # report_to = 'wandb' enable logging to W&B\n       run_name = checkpoint            # name of the W&B run\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T20:29:07.353735Z","iopub.execute_input":"2025-02-13T20:29:07.354084Z","iopub.status.idle":"2025-02-13T20:29:07.384951Z","shell.execute_reply.started":"2025-02-13T20:29:07.354058Z","shell.execute_reply":"2025-02-13T20:29:07.384331Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1688: FutureWarning: `fp16_backend` is deprecated and will be removed in version 5 of 🤗 Transformers. Use `half_precision_backend` instead\n  warnings.warn(\nUsing the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"from sentence_transformers.cross_encoder import CrossEncoder\nimport torch\n#get the eval dataset\nfrom huggingface_hub import hf_hub_download\nhf_hub_download(repo_id=organization_dataset_id, filename=dev_name, local_dir=\"./\", repo_type=\"dataset\")\nimport pickle\nfrom sentence_transformers.cross_encoder.evaluation import CERerankingEvaluator\nwith open(dev_name, 'rb') as f:dev_samples = pickle.load(f)\nevaluator = CERerankingEvaluator(dev_samples, name=\"train-eval\",write_csv=False)\n\ndef compute_metrics(eval_pred):\n    trainer.save_model(\"mymodel\")\n    modelCE = CrossEncoder(\"mymodel\", max_length=256)\n    mrr10 = evaluator(modelCE)\n    return {\"MRR@10\": mrr10}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T20:22:42.566171Z","iopub.execute_input":"2025-02-13T20:22:42.566527Z","iopub.status.idle":"2025-02-13T20:22:43.661532Z","shell.execute_reply.started":"2025-02-13T20:22:42.566489Z","shell.execute_reply":"2025-02-13T20:22:43.660766Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"dev_samples_araelectra.pkl:   0%|          | 0.00/17.7M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7865f2053df04bd59fb7e836be4558c7"}},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"trainer = Trainer(\n        model,\n        training_args,\n        train_dataset=train_dataset[\"train0\"],\n        eval_dataset= train_dataset[\"test\"], \n        callbacks = [EarlyStoppingCallback(early_stopping_patience=10)],\n        tokenizer=tokenizer,\n        compute_metrics=compute_metrics,\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T20:29:14.865211Z","iopub.execute_input":"2025-02-13T20:29:14.865549Z","iopub.status.idle":"2025-02-13T20:29:15.050222Z","shell.execute_reply.started":"2025-02-13T20:29:14.865521Z","shell.execute_reply":"2025-02-13T20:29:15.049412Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-24-8a9889000598>:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"trainer.train()\n#trainer.train(resume_from_checkpoint = True)\n#trainer.save_model()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T20:30:29.941086Z","iopub.execute_input":"2025-02-13T20:30:29.941484Z","iopub.status.idle":"2025-02-13T20:31:11.228732Z","shell.execute_reply.started":"2025-02-13T20:30:29.941444Z","shell.execute_reply":"2025-02-13T20:31:11.227639Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='13' max='234375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [    13/234375 00:32 < 193:14:44, 0.34 it/s, Epoch 0.00/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-25-e4e9187c9f02>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#trainer.train(resume_from_checkpoint = True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#trainer.save_model()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2162\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2163\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2164\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2165\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2166\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2525\u001b[0m                         \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging_nan_inf_filter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2526\u001b[0m                         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_torch_xla_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2527\u001b[0;31m                         \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss_step\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2528\u001b[0m                     ):\n\u001b[1;32m   2529\u001b[0m                         \u001b[0;31m# if loss is nan or inf simply add the average of previous logged losses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":25},{"cell_type":"code","source":"# uncomment to push to yrour huggingface hub\n\"\"\"\nimport huggingface_hub \nhf = huggingface_hub.HfFolder()\naccess_token = \"your access token\"\nhf.save_token(access_token)\nmodel.push_to_hub(\"hatemestinbejaia/\"+checkpoint)\ntokenizer.push_to_hub(\"hatemestinbejaia/\"+checkpoint)\n\"\"\"","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"testmodel = CrossEncoder(checkpoint, max_length=256)\nmrr10 = evaluator(testmodel)\nprint(mrr10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T20:34:06.627834Z","iopub.execute_input":"2025-02-13T20:34:06.628155Z","iopub.status.idle":"2025-02-13T20:38:06.775763Z","shell.execute_reply.started":"2025-02-13T20:34:06.628126Z","shell.execute_reply":"2025-02-13T20:38:06.77483Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/997 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4df926ac6d2f486d856ff86b51eac9c5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/711M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df09e9ae7eaa4133b7105c71f310bdbd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.24k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"63dc9203444d4efabe05242b6f15f341"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b68eacb00ea84d6385ed6216e17d8cb1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.92M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"216f3caa36314c50bbedecca6aa7fda3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da702e44e9734458a05a7d1d1d878f65"}},"metadata":{}},{"name":"stdout","text":"0.6478055555555555\n","output_type":"stream"}],"execution_count":27}]}