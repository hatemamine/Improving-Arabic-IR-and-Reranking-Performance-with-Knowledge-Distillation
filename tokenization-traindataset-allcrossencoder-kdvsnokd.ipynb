{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30775,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/hatemamine/tokenization-traindataset-allcrossencoder-kdvsnokd?scriptVersionId=222419675\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"organization_dataset_id=\"hatemestinbejaia/ExperimentDATA_knowledge_distillation_vs_fine_tuning\"\ndataset_name=\"KD_train_dataset_t05M_t15m_eval_10k_preprocessedAraELECTRA\"\nknowledge_distillation = True\n#model =\"AraELECTRA\"\n#model =\"AraDPR\"\nmodel =\"mMiniLML12v2\"\nif model ==\"AraELECTRA\":\n    args_model=\"aubmindlab/araelectra-base-discriminator\"\n    output = \"train5Mx2tokenized\"+model\nif model ==\"AraDPR\":\n    args_model=\"abdoelsayed/AraDPR\"\n    output = \"train5Mx2tokenized\"+model\nif model ==\"mMiniLML12v2\":\n    args_model=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n    output = \"train5Mx2tokenized\"+model","metadata":{"execution":{"iopub.status.busy":"2025-02-13T19:19:13.155526Z","iopub.execute_input":"2025-02-13T19:19:13.15592Z","iopub.status.idle":"2025-02-13T19:19:13.162203Z","shell.execute_reply.started":"2025-02-13T19:19:13.155884Z","shell.execute_reply":"2025-02-13T19:19:13.160963Z"},"trusted":true},"outputs":[],"execution_count":3},{"cell_type":"code","source":"from datasets import load_from_disk, load_dataset\ntrain_dataset = load_dataset(organization_dataset_id, dataset_name, trust_remote_code=True)","metadata":{"execution":{"iopub.status.busy":"2025-02-13T19:19:16.758477Z","iopub.execute_input":"2025-02-13T19:19:16.7589Z","iopub.status.idle":"2025-02-13T19:23:54.407576Z","shell.execute_reply.started":"2025-02-13T19:19:16.758856Z","shell.execute_reply":"2025-02-13T19:23:54.406331Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/27.2k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"63d95295d2404aa68a9de3c8de979357"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train0-00000-of-00012.parquet:   0%|          | 0.00/165M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"85aaf56b21f142bf8647f5addc4e1e4b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train0-00001-of-00012.parquet:   0%|          | 0.00/168M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9fdca325d8e642dda2d468dab7f63f0b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train0-00002-of-00012.parquet:   0%|          | 0.00/166M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b586ba79dd90430c89bacbed98ee1116"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train0-00003-of-00012.parquet:   0%|          | 0.00/166M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a51fe1669ed54f90ae7ede9de70c9f77"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train0-00004-of-00012.parquet:   0%|          | 0.00/165M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"78ebc3aac4de49da85fe8f4ffd94ea14"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train0-00005-of-00012.parquet:   0%|          | 0.00/165M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"22724ce92af64ee8b8939052131755dd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train0-00006-of-00012.parquet:   0%|          | 0.00/167M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3500702cc0e54e3691cb0bbf93229c07"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train0-00007-of-00012.parquet:   0%|          | 0.00/164M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"46440134a03a45158cce420ac62e8a14"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train0-00008-of-00012.parquet:   0%|          | 0.00/167M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f337890e65740c9b68c768351ae2673"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train0-00009-of-00012.parquet:   0%|          | 0.00/166M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7ba5b0f77b164631b37da0927fb6a123"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train0-00010-of-00012.parquet:   0%|          | 0.00/163M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"feab807e57284f3f97b19a8c708e1b08"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train0-00011-of-00012.parquet:   0%|          | 0.00/166M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"506f3925eb684b0e8ab1bca550701a26"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train1-00000-of-00012.parquet:   0%|          | 0.00/165M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"acffc9f4fd944277b910a9c10c505b39"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train1-00001-of-00012.parquet:   0%|          | 0.00/168M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1059fa7d232c4a8f867c5851538045f6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train1-00002-of-00012.parquet:   0%|          | 0.00/168M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be18cd82b8aa4550aeaa94821e4dea38"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train1-00003-of-00012.parquet:   0%|          | 0.00/165M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ebc5aca99b04062afc05eb14787a6eb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train1-00004-of-00012.parquet:   0%|          | 0.00/167M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e98dbccb36ff43448b226f32a6ef7c02"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train1-00005-of-00012.parquet:   0%|          | 0.00/166M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"56360b9da97d4ff7ae2b8e67e7436cea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train1-00006-of-00012.parquet:   0%|          | 0.00/165M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a37c566eb4a241c195c8b5794259adc2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train1-00007-of-00012.parquet:   0%|          | 0.00/166M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c944a92e743449da997837dc317f9bcd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train1-00008-of-00012.parquet:   0%|          | 0.00/165M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e1b4bd9bf29b45ea8c97218d1ef0c471"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train1-00009-of-00012.parquet:   0%|          | 0.00/165M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c9cea4024444daeb4a2ff6368cc5bc8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train1-00010-of-00012.parquet:   0%|          | 0.00/166M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d4aee854236f4707a8e7910b44ef7579"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train1-00011-of-00012.parquet:   0%|          | 0.00/166M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e7d443160dc4170bf90e06a863168e3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train2-00000-of-00012.parquet:   0%|          | 0.00/168M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0abea463229c4211afbc3e8d098fd2bd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train2-00001-of-00012.parquet:   0%|          | 0.00/168M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6a1780434274b8380ffbb4ae34c35c8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train2-00002-of-00012.parquet:   0%|          | 0.00/167M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"542597c6ce694e968d9eb931c3de28eb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train2-00003-of-00012.parquet:   0%|          | 0.00/166M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c7bb76555c43487fba5f0f69b6c04dbd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train2-00004-of-00012.parquet:   0%|          | 0.00/166M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1de051e69ba946ecb3382264d4021e84"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train2-00005-of-00012.parquet:   0%|          | 0.00/166M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29bc90bc19b24baaa518fde854454bc9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train2-00006-of-00012.parquet:   0%|          | 0.00/167M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b253339d8804e249269fc98d7e692f8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train2-00007-of-00012.parquet:   0%|          | 0.00/168M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2223f7b315c2473abe41dba2e28a9c5e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train2-00008-of-00012.parquet:   0%|          | 0.00/166M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"37525e668f1f4e7a99a6677e48bec8a5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train2-00009-of-00012.parquet:   0%|          | 0.00/167M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3bde609075b644adbda9cfa9480b57e3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train2-00010-of-00012.parquet:   0%|          | 0.00/167M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"353458376b7645acbcb181c6e90f4d12"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train2-00011-of-00012.parquet:   0%|          | 0.00/165M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a22b8e0bbfa248c3b533e47ae3d743e1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00000-of-00001.parquet:   0%|          | 0.00/3.95M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f861121488c24ac9b208d91631440421"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train0 split:   0%|          | 0/5000000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8de9347355fe42c5b542ba534e91a1c3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train1 split:   0%|          | 0/5000000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4adc689bf3434546b33ef601dda378d0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train2 split:   0%|          | 0/5000000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eed02b0d742343fea501529b1d5f3fa6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca487f1d2fb54efeb1b280c26b517a7c"}},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"train_dataset","metadata":{"execution":{"iopub.status.busy":"2025-02-13T19:27:00.660107Z","iopub.execute_input":"2025-02-13T19:27:00.660802Z","iopub.status.idle":"2025-02-13T19:27:00.670725Z","shell.execute_reply.started":"2025-02-13T19:27:00.660763Z","shell.execute_reply":"2025-02-13T19:27:00.669469Z"},"trusted":true},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train0: Dataset({\n        features: ['pos_score', 'neg_score', 'query', 'pos', 'neg', 'label'],\n        num_rows: 5000000\n    })\n    train1: Dataset({\n        features: ['pos_score', 'neg_score', 'query', 'pos', 'neg', 'label'],\n        num_rows: 5000000\n    })\n    train2: Dataset({\n        features: ['pos_score', 'neg_score', 'query', 'pos', 'neg', 'label'],\n        num_rows: 5000000\n    })\n    test: Dataset({\n        features: ['pos_score', 'neg_score', 'query', 'pos', 'neg', 'label'],\n        num_rows: 10000\n    })\n})"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"train_dataset[\"train0\"][0]","metadata":{"execution":{"iopub.status.busy":"2025-02-13T19:27:05.144479Z","iopub.execute_input":"2025-02-13T19:27:05.144904Z","iopub.status.idle":"2025-02-13T19:27:05.163562Z","shell.execute_reply.started":"2025-02-13T19:27:05.144868Z","shell.execute_reply":"2025-02-13T19:27:05.16238Z"},"trusted":true},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"{'pos_score': 6.624662319819133,\n 'neg_score': 2.596603328982989,\n 'query': 'القليل من الكافيين جيد أثناء الحمل',\n 'pos': 'نحن لا نعرف الكثير عن تأثيرات الكافيين أثناء الحمل عليك وعلى طفلك . لذلك فمن الأفضل أن تحد من المبلغ الذي تحصل عليه كل يوم . إذا كنت حاملا ، قللي من تناول الكافيين إلى 200 ملليجرام يوميا . هذا هو الكمية الموجودة في فنجان واحد سعة 8 أونصات من القهوة أو فنجان قهوة سعة 12 أونصة .',\n 'neg': 'من الآمن عموما أن تتناول النساء الحوامل الشوكولاتة لأن الدراسات أثبتت وجود فوائد معينة لتناول الشوكولاتة أثناء الحمل . ومع ذلك ، يجب على النساء الحوامل التأكد من أن تناول الكافيين أقل من 200 مجم في اليوم .',\n 'label': 4.0280589908361435}"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"import numpy as np\nmins =min(np.min(train_dataset[\"train0\"]['pos_score']), np.min(train_dataset[\"train0\"]['neg_score']), np.min(train_dataset[\"train1\"]['pos_score']), np.min(train_dataset[\"train1\"]['neg_score']), np.min(train_dataset[\"train2\"]['pos_score']), np.min(train_dataset[\"train2\"]['neg_score']), np.min(train_dataset[\"test\"]['pos_score']), np.min(train_dataset[\"test\"]['neg_score']))\nmaxs =max(np.max(train_dataset[\"train0\"]['pos_score']), np.max(train_dataset[\"train0\"]['neg_score']), np.max(train_dataset[\"train1\"]['pos_score']), np.max(train_dataset[\"train1\"]['neg_score']), np.max(train_dataset[\"train2\"]['pos_score']), np.max(train_dataset[\"train2\"]['neg_score']), np.max(train_dataset[\"test\"]['pos_score']), np.max(train_dataset[\"test\"]['neg_score']))\nprint(mins, maxs)","metadata":{"execution":{"iopub.status.busy":"2025-02-13T19:27:12.124522Z","iopub.execute_input":"2025-02-13T19:27:12.124932Z","iopub.status.idle":"2025-02-13T19:27:47.860838Z","shell.execute_reply.started":"2025-02-13T19:27:12.124897Z","shell.execute_reply":"2025-02-13T19:27:47.859639Z"},"trusted":true},"outputs":[{"name":"stdout","text":"-11.97320302327474 11.491349379221598\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"def reformule_examples_with_KD(examples):\n    query = []\n    passage=[]\n    label=[]\n    for i in range (len(examples[\"query\"])):\n        query.append(examples[\"query\"][i])\n        query.append(examples[\"query\"][i])\n        passage.append(examples[\"pos\"][i])\n        passage.append(examples[\"neg\"][i])\n        label.append((examples[\"pos_score\"][i]-mins)/(maxs-mins))\n        label.append((examples[\"neg_score\"][i]-mins)/(maxs-mins))\n    return {\"query\": query, \"passage\": passage, \"label\": label}","metadata":{"execution":{"iopub.status.busy":"2025-02-13T19:27:47.863415Z","iopub.execute_input":"2025-02-13T19:27:47.86391Z","iopub.status.idle":"2025-02-13T19:27:47.872073Z","shell.execute_reply.started":"2025-02-13T19:27:47.863854Z","shell.execute_reply":"2025-02-13T19:27:47.87074Z"},"trusted":true},"outputs":[],"execution_count":8},{"cell_type":"code","source":"def reformule_examples_with_NoKD(examples):\n    query = []\n    passage=[]\n    label=[]\n    for i in range (len(examples[\"query\"])):\n        query.append(examples[\"query\"][i])\n        query.append(examples[\"query\"][i])\n        passage.append(examples[\"pos\"][i])\n        passage.append(examples[\"neg\"][i])\n        label.append(1.0)\n        label.append(0.0)\n    return {\"query\": query, \"passage\": passage, \"label\": label}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T19:27:47.87395Z","iopub.execute_input":"2025-02-13T19:27:47.874467Z","iopub.status.idle":"2025-02-13T19:27:47.891557Z","shell.execute_reply.started":"2025-02-13T19:27:47.874417Z","shell.execute_reply":"2025-02-13T19:27:47.890489Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"if knowledge_distillation :\n    train_dataset[\"train0\"] = train_dataset[\"train0\"].map(reformule_examples_with_KD, batched=True, remove_columns=['query', 'pos', 'neg', 'pos_score', 'neg_score', 'label'])\n    train_dataset[\"test\"] = train_dataset[\"test\"].map(reformule_examples_with_KD, batched=True, remove_columns=['query', 'pos', 'neg', 'pos_score', 'neg_score', 'label'])\n    output= \"KD\"+output\nelse:\n    train_dataset[\"train0\"] = train_dataset[\"train0\"].map(reformule_examples_with_NoKD, batched=True, remove_columns=['query', 'pos', 'neg', 'pos_score', 'neg_score', 'label'])\n    train_dataset[\"test\"] = train_dataset[\"test\"].map(reformule_examples_with_NoKD, batched=True, remove_columns=['query', 'pos', 'neg', 'pos_score', 'neg_score', 'label'])","metadata":{"execution":{"iopub.status.busy":"2025-02-13T19:28:33.907744Z","iopub.execute_input":"2025-02-13T19:28:33.908186Z","iopub.status.idle":"2025-02-13T19:32:30.980563Z","shell.execute_reply.started":"2025-02-13T19:28:33.908131Z","shell.execute_reply":"2025-02-13T19:32:30.978958Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/5000000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c80d8a4d45ba4689a8117ea6d254e14f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e85656abaf247879a0f9c7c7c0152f4"}},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"from transformers import AutoTokenizer\ntokenizer = AutoTokenizer.from_pretrained(args_model)\ndef tokenize(batch):\n    tokenized = tokenizer(\n        batch[\"query\"],\n        batch[\"passage\"],\n        truncation=\"only_second\",\n        max_length=256,\n        padding='max_length',\n        )\n    tokenized[\"labels\"] = [[float(label)] for label in batch[\"label\"]]\n    return tokenized\n\ntrain_dataset[\"train0\"] = train_dataset[\"train0\"].map(tokenize, batched=True, remove_columns=[\"query\", \"passage\", \"label\"])\ntrain_dataset[\"test\"] = train_dataset[\"test\"].map(tokenize, batched=True, remove_columns=[\"query\", \"passage\", \"label\"])","metadata":{"execution":{"iopub.status.busy":"2025-02-13T19:34:54.221297Z","iopub.execute_input":"2025-02-13T19:34:54.221763Z","iopub.status.idle":"2025-02-13T20:38:20.70082Z","shell.execute_reply.started":"2025-02-13T19:34:54.221723Z","shell.execute_reply":"2025-02-13T20:38:20.699408Z"},"trusted":true},"outputs":[{"name":"stderr","text":"The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"33476f92e75549eaa8f9bb9b94acedd3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/480 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc763a34f73f48f09d1174cd32fdf406"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/645 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c83e7568f3f347d6aeb05d2a4b1f2808"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.08M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25975edbfd244f2bbba9c4aa65a5924d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"06c25e17282b41e4baadda0b05d046f1"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/10000000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5abe8ff76d674b16941d14fd4d973f03"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/20000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac216e33340c47c599bf580c481e2a6a"}},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"from datasets import DatasetDict\ndatasets = DatasetDict({\n    \"train0\": train_dataset[\"train0\"],\n    \"test\": train_dataset[\"test\"]})","metadata":{"execution":{"iopub.status.busy":"2025-02-13T20:38:20.703254Z","iopub.execute_input":"2025-02-13T20:38:20.703604Z","iopub.status.idle":"2025-02-13T20:38:20.709197Z","shell.execute_reply.started":"2025-02-13T20:38:20.70357Z","shell.execute_reply":"2025-02-13T20:38:20.708119Z"},"trusted":true},"outputs":[],"execution_count":13},{"cell_type":"code","source":"datasets.set_format(\"torch\")\nprint(datasets)\nprint(output)","metadata":{"execution":{"iopub.status.busy":"2025-02-13T20:39:07.895559Z","iopub.execute_input":"2025-02-13T20:39:07.896001Z","iopub.status.idle":"2025-02-13T20:39:07.904515Z","shell.execute_reply.started":"2025-02-13T20:39:07.895964Z","shell.execute_reply":"2025-02-13T20:39:07.903213Z"},"trusted":true},"outputs":[{"name":"stdout","text":"DatasetDict({\n    train0: Dataset({\n        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n        num_rows: 10000000\n    })\n    test: Dataset({\n        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n        num_rows: 20000\n    })\n})\nKDtrain5Mx2tokenizedmMiniLML12v2\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# to puch in your huggingface roposit uncomment\n\"\"\"\nimport huggingface_hub \nhf = huggingface_hub.HfFolder()\naccess_token = \"your access token\"\nhf.save_token(access_token)\norganization_dataset_id=\"your huggingface reposit\"\ndatasets.push_to_hub(organization_dataset_id, output)\n\"\"\"\n#if you went to save it localy\n#train_dataset.save_to_disk(output)","metadata":{"execution":{"iopub.status.busy":"2025-02-13T19:18:37.767142Z","iopub.status.idle":"2025-02-13T19:18:37.767621Z","shell.execute_reply.started":"2025-02-13T19:18:37.767435Z","shell.execute_reply":"2025-02-13T19:18:37.767455Z"},"trusted":true},"outputs":[],"execution_count":null}]}