{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 30822,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hatemamine/Improving-Arabic-IR-and-Reranking-Performance-with-Knowledge-Distillation/blob/main/mrtydi_firststage_faiss_kd_vs_nokd_bi_encoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/facebookresearch/faiss/wiki/Running-on-GPUs"
      ],
      "metadata": {
        "id": "483d5T-JRwqY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-cpu -q\n",
        "!pip install huggingface_hub -q"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-13T10:27:30.788799Z",
          "iopub.execute_input": "2025-02-13T10:27:30.789218Z",
          "iopub.status.idle": "2025-02-13T10:27:39.746145Z",
          "shell.execute_reply.started": "2025-02-13T10:27:30.789190Z",
          "shell.execute_reply": "2025-02-13T10:27:39.744584Z"
        },
        "id": "7HE7t8LkRwqb"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# embedding vector generated with our bi-encoder model\n",
        "organization_dataset_id=\"hatemestinbejaia/ExperimentDATA_knowledge_distillation_vs_fine_tuning\"\n",
        "mrTydi_embedding_collection_list =[\"mrTydi-collection-arabic-embedding-KDaradpr\", \"mrTydi-collection-arabic-embedding-NOKDaradpr\", \"mrTydi-collection-arabic-embedding-mmarco-Arabic-AraElectra-bi-encoder-KD-v1\", \"mrTydi-collection-arabic-embedding-mmarco-Arabic-AraElectra-bi-encoder-NoKD-v1\", \"mrTydi-collection-arabic-embedding-mmarco-Arabic-mMiniLML-bi-encoder-KD-v1\", \"mrTydi-collection-arabic-embedding-mmarco-Arabic-mMiniLML-bi-encoder-NoKD-v1\"]\n",
        "mrTydi_embedding_queries_list=[\"mrTydi-queries-arabic-embedding-KDaradpr\", \"mrTydi-queries-arabic-embedding-NOKDaradpr\", \"mrTydi-queries-arabic-embedding-mmarco-Arabic-AraElectra-bi-encoder-KD-v1\", \"mrTydi-queries-arabic-embedding-mmarco-Arabic-AraElectra-bi-encoder-NoKD-v1\", \"mrTydi-queries-arabic-embedding-mmarco-Arabic-mMiniLML-bi-encoder-KD-v1\", \"mrTydi-queries-arabic-embedding-mmarco-Arabic-mMiniLML-bi-encoder-NoKD-v1\"]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-13T10:39:58.139855Z",
          "iopub.execute_input": "2025-02-13T10:39:58.140465Z",
          "iopub.status.idle": "2025-02-13T10:39:58.145760Z",
          "shell.execute_reply.started": "2025-02-13T10:39:58.140430Z",
          "shell.execute_reply": "2025-02-13T10:39:58.144513Z"
        },
        "id": "FdMwbUyKRwqd"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import gc\n",
        "from datasets import load_dataset\n",
        "output_run=\"first_stage_\"\n",
        "def combine_embedding(embedding1, embedding2):\n",
        "    global output_run\n",
        "    output_run+= mrTydi_embedding_collection_list[embedding1]+mrTydi_embedding_collection_list[embedding2]\n",
        "    # load corpus embedding\n",
        "    corpus_embeddings0 = load_dataset(organization_dataset_id, mrTydi_embedding_collection_list[embedding1])\n",
        "    print(corpus_embeddings0)\n",
        "    corpus_embeddings1 = load_dataset(organization_dataset_id, mrTydi_embedding_collection_list[embedding2])\n",
        "    print(corpus_embeddings1)\n",
        "    corpus_embeddings0=corpus_embeddings0[\"train\"].with_format(\"np\")\n",
        "    corpus_id=corpus_embeddings0[\"docid\"]\n",
        "    corpus_embeddings0=corpus_embeddings0[\"embedding\"]\n",
        "    corpus_embeddings0\n",
        "    # concatenate  embedding\n",
        "    corpus_embeddings1=corpus_embeddings1[\"train\"].with_format(\"np\")\n",
        "    corpus_embeddings1=corpus_embeddings1[\"embedding\"]\n",
        "    corpus_embeddings1\n",
        "    corpus_embeddings =np.concatenate((corpus_embeddings0,corpus_embeddings1),1)\n",
        "    del corpus_embeddings0\n",
        "    del corpus_embeddings1\n",
        "    # Force a garbage collection\n",
        "    gc.collect()\n",
        "    # load queries embedding\n",
        "    queries_embeddings0 = load_dataset(organization_dataset_id, mrTydi_embedding_queries_list[embedding1], trust_remote_code=True)\n",
        "    queries_embeddings1 = load_dataset(organization_dataset_id, mrTydi_embedding_queries_list[embedding2], trust_remote_code=True)\n",
        "    queries_embeddings0 = queries_embeddings0[\"train\"].with_format(\"np\")\n",
        "    queries_embeddings1 = queries_embeddings1[\"train\"].with_format(\"np\")\n",
        "    queries_id=queries_embeddings0[\"id\"]\n",
        "    queries_embeddings0=queries_embeddings0[\"embedding\"]\n",
        "    queries_embeddings1=queries_embeddings1[\"embedding\"]\n",
        "    queries_embeddings =np.concatenate((queries_embeddings0,queries_embeddings1),1)\n",
        "    #print(queries_embeddings)\n",
        "    print(len(queries_embeddings[0]))\n",
        "    return corpus_embeddings,corpus_id, queries_embeddings, queries_id\n",
        "\n",
        "def load_embedding(embedding):\n",
        "    global output_run\n",
        "    output_run+= mrTydi_embedding_collection_list[embedding]\n",
        "    # load corpus embedding\n",
        "    corpus_embeddings = load_dataset(organization_dataset_id, mrTydi_embedding_collection_list[embedding])\n",
        "    print(corpus_embeddings)\n",
        "    corpus_embeddings=corpus_embeddings[\"train\"].with_format(\"np\")\n",
        "    corpus_id=corpus_embeddings[\"docid\"]\n",
        "    corpus_embeddings=corpus_embeddings[\"embedding\"]\n",
        "    corpus_embeddings\n",
        "    # Force a garbage collection\n",
        "    gc.collect()\n",
        "    # load queries embedding\n",
        "    queries_embeddings = load_dataset(organization_dataset_id, mrTydi_embedding_queries_list[embedding], trust_remote_code=True)\n",
        "    queries_embeddings = queries_embeddings[\"train\"].with_format(\"np\")\n",
        "    queries_id=queries_embeddings[\"id\"]\n",
        "    queries_embeddings=queries_embeddings[\"embedding\"]\n",
        "    #print(queries_embeddings)\n",
        "    print(len(queries_embeddings[0]))\n",
        "    return corpus_embeddings,corpus_id, queries_embeddings, queries_id"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-13T11:09:59.905555Z",
          "iopub.execute_input": "2025-02-13T11:09:59.906062Z",
          "iopub.status.idle": "2025-02-13T11:09:59.917000Z",
          "shell.execute_reply.started": "2025-02-13T11:09:59.906028Z",
          "shell.execute_reply": "2025-02-13T11:09:59.915214Z"
        },
        "id": "m_BsCkcaRwqe"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# you can combine embedding vector from diffrent bi-encoder model\n",
        "combine=False\n",
        "if combine:corpus_embeddings,corpus_id, queries_embeddings, queries_id=combine_embedding(0, 4)\n",
        "else: corpus_embeddings,corpus_id, queries_embeddings, queries_id=load_embedding(4)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-13T11:10:12.889146Z",
          "iopub.execute_input": "2025-02-13T11:10:12.889780Z",
          "iopub.status.idle": "2025-02-13T11:10:25.665649Z",
          "shell.execute_reply.started": "2025-02-13T11:10:12.889737Z",
          "shell.execute_reply": "2025-02-13T11:10:25.664420Z"
        },
        "id": "g_fRM1UFRwqf"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "This example uses Approximate Nearest Neighbor Search (ANN) with FAISS (https://github.com/facebookresearch/faiss).\n",
        "\"\"\"\n",
        "\n",
        "import csv\n",
        "import os\n",
        "import pickle\n",
        "import time\n",
        "\n",
        "import faiss\n",
        "import numpy as np\n",
        "\n",
        "embedding_size = len(corpus_embeddings[0])  # Size of embeddings\n",
        "# Defining our FAISS index\n",
        "# Number of clusters used for faiss. Select a value 4*sqrt(N) to 16*sqrt(N) - https://github.com/facebookresearch/faiss/wiki/Guidelines-to-choose-an-index\n",
        "#n_clusters = 10\n",
        "# We use Inner Product (dot-product) as Index. We will normalize our vectors to unit length, then is Inner Product equal to cosine similarity\n",
        "#quantizer = faiss.IndexFlatIP(embedding_size)\n",
        "#print(\"quantizer\")\n",
        "#index = faiss.IndexIVFFlat(quantizer, embedding_size, n_clusters, faiss.METRIC_INNER_PRODUCT)\n",
        "#print(\"index\")\n",
        "# Number of clusters to explorer at search time. We will search for nearest neighbors in 3 clusters.\n",
        "#index.nprobe = 10\n",
        "\n",
        "### Create the FAISS index\n",
        "print(\"Start creating FAISS index\")\n",
        "#index = faiss.IndexIDMap(faiss.IndexFlatL2(embedding_size))\n",
        "#index = faiss.IndexFlatL2(embedding_size)\n",
        "index = faiss.index_factory(embedding_size, \"Flat\", faiss.METRIC_INNER_PRODUCT)\n",
        "#corpus_embeddings = corpus_embeddings / np.linalg.norm(corpus_embeddings, axis=1)[:, None]\n",
        "faiss.normalize_L2(corpus_embeddings)\n",
        "# First, we need to normalize vectors to unit length\n",
        "#corpus_embeddings = corpus_embeddings / np.linalg.norm(corpus_embeddings, axis=1)[:, None]\n",
        "print(\"norm\")\n",
        "# Then we train the index to find a suitable clustering\n",
        "index.train(corpus_embeddings)\n",
        "print(\"train\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-13T10:54:46.991242Z",
          "iopub.execute_input": "2025-02-13T10:54:46.991646Z",
          "iopub.status.idle": "2025-02-13T10:54:47.195802Z",
          "shell.execute_reply.started": "2025-02-13T10:54:46.991615Z",
          "shell.execute_reply": "2025-02-13T10:54:47.194870Z"
        },
        "id": "5CzzK49tRwqg"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "faiss.write_index(index,\"mrTydi.index\")\n",
        "index = faiss.read_index(\"mrTydi.index\")\n",
        "index.add(corpus_embeddings)\n",
        "faiss.write_index(index, \"mrTydi.index\")\n",
        "print(\"faiss index built it ok\")\n",
        "print(\"total index:\",index.ntotal)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-13T10:54:52.767879Z",
          "iopub.execute_input": "2025-02-13T10:54:52.768310Z",
          "iopub.status.idle": "2025-02-13T10:55:05.082787Z",
          "shell.execute_reply.started": "2025-02-13T10:54:52.768269Z",
          "shell.execute_reply": "2025-02-13T10:55:05.081109Z"
        },
        "id": "E-ie48rRRwqh"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#print(queries_embeddings[0])\n",
        "top_k_hits = 1000\n",
        "output_run += \"_top_k_hits_\"+str(top_k_hits) +\".tsv\"\n",
        "print(output_run)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-13T11:04:37.659989Z",
          "iopub.execute_input": "2025-02-13T11:04:37.660368Z",
          "iopub.status.idle": "2025-02-13T11:04:37.665418Z",
          "shell.execute_reply.started": "2025-02-13T11:04:37.660339Z",
          "shell.execute_reply": "2025-02-13T11:04:37.663903Z"
        },
        "id": "l_XIY1wcRwqi"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_id"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-13T11:10:32.523687Z",
          "iopub.execute_input": "2025-02-13T11:10:32.524093Z",
          "iopub.status.idle": "2025-02-13T11:10:32.530970Z",
          "shell.execute_reply.started": "2025-02-13T11:10:32.524064Z",
          "shell.execute_reply": "2025-02-13T11:10:32.529724Z"
        },
        "id": "W9mTxP8dRwqi"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "######### Search in the index ###########\n",
        "import time\n",
        "import numpy as np\n",
        "from tqdm import trange\n",
        "with open(output_run, 'w', encoding='utf-8') as f_out:\n",
        "    for i in trange(len(queries_embeddings)):\n",
        "        start_time = time.time()\n",
        "        question_embedding = queries_embeddings[i]\n",
        "        # FAISS works with inner product (dot product). When we normalize vectors to unit length, inner product is equal to cosine similarity\n",
        "        #question_embedding = question_embedding / np.linalg.norm(question_embedding)\n",
        "        question_embedding = np.expand_dims(question_embedding, axis=0)\n",
        "        faiss.normalize_L2(question_embedding)\n",
        "\n",
        "        # Search in FAISS. It returns a matrix with distances and corpus ids.\n",
        "        distances, corpus_ids = index.search(question_embedding, top_k_hits)\n",
        "\n",
        "        # We extract corpus ids and scores for the first query\n",
        "        hits = [{\"corpus_id\": id, \"score\": score} for id, score in zip(corpus_ids[0], distances[0])]\n",
        "        #print(hits)\n",
        "        hits = sorted(hits, key=lambda x: x[\"score\"], reverse=True)\n",
        "        end_time = time.time()\n",
        "        for j in range(len(hits)):\n",
        "            f_out.write(f'{queries_id[i]}\\t{corpus_id[hits[j][\"corpus_id\"]]}\\t{j+1}\\n')\n",
        "        #break"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-13T11:12:12.160726Z",
          "iopub.execute_input": "2025-02-13T11:12:12.161118Z",
          "iopub.status.idle": "2025-02-13T11:18:12.980690Z",
          "shell.execute_reply.started": "2025-02-13T11:12:12.161085Z",
          "shell.execute_reply": "2025-02-13T11:18:12.979477Z"
        },
        "id": "bhHJVLOPRwqj"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(end_time-start_time)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-13T11:11:13.736559Z",
          "iopub.execute_input": "2025-02-13T11:11:13.736904Z",
          "iopub.status.idle": "2025-02-13T11:11:13.742533Z",
          "shell.execute_reply.started": "2025-02-13T11:11:13.736879Z",
          "shell.execute_reply": "2025-02-13T11:11:13.741276Z"
        },
        "id": "ykJ5ISvhRwqk"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U datasets huggingface-hub -q\n",
        "import huggingface_hub\n",
        "hf = huggingface_hub.HfFolder()\n",
        "# to load the reranked list to your Hugging Face repository, enter your access token below.\n",
        "# and change the repository ID to yours.\n",
        "#organization_dataset_id =\"\"\n",
        "access_token = \"Hagging face access token\"\n",
        "hf.save_token(access_token)\n",
        "from huggingface_hub import HfApi\n",
        "api = HfApi()\n",
        "#api.upload_file(path_or_fileobj=output_run, path_in_repo=output_run, repo_id=organization_dataset_id, repo_type=\"dataset\",)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-08T09:48:01.123028Z",
          "iopub.execute_input": "2025-01-08T09:48:01.123495Z",
          "iopub.status.idle": "2025-01-08T09:48:11.705267Z",
          "shell.execute_reply.started": "2025-01-08T09:48:01.123458Z",
          "shell.execute_reply": "2025-01-08T09:48:11.704077Z"
        },
        "id": "hlZXldxCRwql"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}