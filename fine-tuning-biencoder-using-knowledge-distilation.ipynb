{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":211427667,"sourceType":"kernelVersion"}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/hatemamine/fine-tuning-biencoder-using-knowledge-distilation?scriptVersionId=222423161\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"%env PATH=/usr/local/cuda/bin:/opt/conda/bin:/opt/conda/condabin:/opt/conda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin!pip install huggingface_hub -q!pip install datasets -q!pip install torch -q!pip install transformers -q!pip install tensorflow-cpu==2.16.1 -q!pip install tf-keras==2.16.0 --no-dependencies -q!pip install wandb -q!pip install -U accelerate -q!pip install -U transformers[torch]==4.45.2 -q!pip install sentence_transformers==3.1.1 -q","metadata":{}},{"cell_type":"code","source":"organization_dataset_id=\"hatemestinbejaia/ExperimentDATA_knowledge_distillation_vs_fine_tuning\"\n#model =\"mmarco-Arabic-AraElectra-bi-encoder-NoKD-v1\"\n#model =\"mmarco-Arabic-AraDPR-bi-encoder-NoKD-v1\"\n#model =\"mmarco-Arabic-mMiniLML-bi-encoder-NoKD-v1\"\n# fine-tuning using knowledge distilation\n#model =\"mmarco-Arabic-AraElectra-bi-encoder-KD-v1\"\n#model =\"mmarco-Arabic-AraDPR-bi-encoder-KD-v1\"\nmodel =\"mmarco-Arabic-mMiniLML-bi-encoder-KD-v1\"\ndataset_name= \"KD_train_dataset_t05M_t15m_eval_10k_preprocessedAraELECTRA\"\ndev_name= \"dev_samples_araelectra.pkl\"\nif model ==\"mmarco-Arabic-AraElectra-bi-encoder-KD-v1\":    \n    args_model=\"aubmindlab/araelectra-base-discriminator\"    \nif model ==\"mmarco-Arabic-AraElectra-bi-encoder-NoKD-v1\" :    \n    args_model=\"aubmindlab/araelectra-base-discriminator\"    \nif model ==\"mmarco-Arabic-AraDPR-bi-encoder-NoKD-v1\" :    \n    args_model=\"abdoelsayed/AraDPR\"    \nif model ==\"mmarco-Arabic-AraDPR-bi-encoder-KD-v1\" :    \n    args_model=\"abdoelsayed/AraDPR\"    \nif model ==\"mmarco-Arabic-mMiniLML-bi-encoder-NoKD-v1\" :    \n    args_model=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"    \nif model ==\"mmarco-Arabic-mMiniLML-bi-encoder-KD-v1\" :    \n    args_model=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\" \ncheckpoint =model","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install sentence_transformers -q\n!pip install huggingface_hub -q\n!pip install wandb -q","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#get the train dataset\nfrom datasets import load_from_disk, load_dataset\ntrain_dataset = load_dataset(organization_dataset_id, dataset_name, trust_remote_code=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dataset = train_dataset.remove_columns(['pos_score', 'neg_score'])\nprint(train_dataset)\ntrain_dataset[\"train0\"][0]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom datasets import load_dataset\nfrom datetime  import datetime\nfrom sentence_transformers import SentenceTransformer, SentenceTransformerTrainer, losses\nfrom sentence_transformers.training_args import SentenceTransformerTrainingArguments\nfrom datasets import Dataset\nfrom sentence_transformers.evaluation import TripletEvaluator, RerankingEvaluator\nfrom transformers import EarlyStoppingCallback","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModel\ntokenizer  = AutoTokenizer.from_pretrained(args_model)\nmodel = SentenceTransformer(args_model)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# to use wandb uncomment and change report_to = 'wandb' in TrainingArguments\n\"\"\"\nimport wandb\nimport os\nos.environ[\"WANDB_API_KEY\"] = \"your wandb api key\"\n\"\"\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import accelerate\nimport transformers\ntransformers.__version__, accelerate.__version__\ndevice = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\nprint(device)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"eval_steps =2000\nfrom transformers import EarlyStoppingCallback, IntervalStrategy\ntraining_args = SentenceTransformerTrainingArguments(        \n    f\"training_with_callbacks\",        \n    evaluation_strategy = IntervalStrategy.STEPS, # \"steps\"        \n    eval_steps = eval_steps, # Evaluation and Save happens every 50 steps        \n    save_total_limit = 2,        \n    save_steps= eval_steps,        \n    fp16=True,        \n    fp16_backend=\"amp\",        \n    per_device_train_batch_size=16,         \n    gradient_accumulation_steps=8,        \n    logging_steps=eval_steps,        \n    warmup_ratio=0.07,        \n    num_train_epochs=3,         \n    learning_rate = 7e-5,        \n    weight_decay= 0.0,        \n    metric_for_best_model = 'eval_mrr@10',        \n    greater_is_better=True,       \n    load_best_model_at_end=True,       \n    report_to = None,             # report_to = 'wandb' enable logging to W&B       \n    run_name = checkpoint            # name of the W&B run    \n   )","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\n#get the eval dataset\nfrom huggingface_hub import hf_hub_download\nhf_hub_download(repo_id=organization_dataset_id, filename=dev_name, local_dir=\"./\", repo_type=\"dataset\")\nimport pickle\nfrom sentence_transformers.cross_encoder.evaluation  import CERerankingEvaluator\nwith open(dev_name, 'rb') as f : dev_samples = pickle.load(f)\nRerankingEvaluator(dev_samples)\n#results = triplet_evaluator(student_model)# In this example, the labels become -0.036 and 0.68, respectively\n#loss = losses.MarginMSELoss(model)\n#train_loss = losses.MultipleNegativesRankingLoss(model=model)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from __future__ import annotations\nfrom sklearn.preprocessing import normalize\nfrom collections.abc import Iterable\n\nfrom torch import Tensor, nn\nimport torch.nn.functional as F\n\nfrom sentence_transformers import SentenceTransformer, util\n\n\nclass MarginMSELoss(nn.Module):\n    def __init__(self, model: SentenceTransformer, similarity_fct=util.pairwise_dot_score) -> None:\n        \"\"\"\n        Compute the MSE loss between the ``|sim(Query, Pos) - sim(Query, Neg)|`` and ``|gold_sim(Query, Pos) - gold_sim(Query, Neg)|``.\n        By default, sim() is the dot-product. The gold_sim is often the similarity score from a teacher model.\n\n        In contrast to :class:`MultipleNegativesRankingLoss`, the two passages do not have to be strictly positive and negative,\n        both can be relevant or not relevant for a given query. This can be an advantage of MarginMSELoss over\n        MultipleNegativesRankingLoss, but note that the MarginMSELoss is much slower to train. With MultipleNegativesRankingLoss,\n        with a batch size of 64, we compare one query against 128 passages. With MarginMSELoss, we compare a query only\n        against two passages.\n\n        Args:\n            model: SentenceTransformerModel\n            similarity_fct: Which similarity function to use.\n\n        References:\n            - For more details, please refer to https://arxiv.org/abs/2010.02666.\n            - `Training Examples > MS MARCO <../../examples/training/ms_marco/README.html>`_\n            - `Unsupervised Learning > Domain Adaptation <../../examples/domain_adaptation/README.html>`_\n\n        Requirements:\n            1. (query, passage_one, passage_two) triplets\n            2. Usually used with a finetuned teacher M in a knowledge distillation setup\n\n        Inputs:\n            +-----------------------------------------------+-----------------------------------------------+\n            | Texts                                         | Labels                                        |\n            +===============================================+===============================================+\n            | (query, passage_one, passage_two) triplets    | M(query, passage_one) - M(query, passage_two) |\n            +-----------------------------------------------+-----------------------------------------------+\n\n        Relations:\n            - :class:`MSELoss` is equivalent to this loss, but without a margin through the negative pair.\n\n        Example:\n\n            With gold labels, e.g. if you have hard scores for sentences. Imagine you want a model to embed sentences\n            with similar \"quality\" close to each other. If the \"text1\" has quality 5 out of 5, \"text2\" has quality\n            1 out of 5, and \"text3\" has quality 3 out of 5, then the similarity of a pair can be defined as the\n            difference of the quality scores. So, the similarity between \"text1\" and \"text2\" is 4, and the\n            similarity between \"text1\" and \"text3\" is 2. If we use this as our \"Teacher Model\", the label becomes\n            similraity(\"text1\", \"text2\") - similarity(\"text1\", \"text3\") = 4 - 2 = 2.\n\n            Positive values denote that the first passage is more similar to the query than the second passage,\n            while negative values denote the opposite.\n\n            ::\n\n                from sentence_transformers import SentenceTransformer, SentenceTransformerTrainer, losses\n                from datasets import Dataset\n\n                model = SentenceTransformer(\"microsoft/mpnet-base\")\n                train_dataset = Dataset.from_dict({\n                    \"text1\": [\"It's nice weather outside today.\", \"He drove to work.\"],\n                    \"text2\": [\"It's so sunny.\", \"He took the car to work.\"],\n                    \"text3\": [\"It's very sunny.\", \"She walked to the store.\"],\n                    \"label\": [0.1, 0.8],\n                })\n                loss = losses.MarginMSELoss(model)\n\n                trainer = SentenceTransformerTrainer(\n                    model=model,\n                    train_dataset=train_dataset,\n                    loss=loss,\n                )\n                trainer.train()\n\n            We can also use a teacher model to compute the similarity scores. In this case, we can use the teacher model\n            to compute the similarity scores and use them as the silver labels. This is often used in knowledge distillation.\n\n            ::\n\n                from sentence_transformers import SentenceTransformer, SentenceTransformerTrainer, losses\n                from datasets import Dataset\n\n                student_model = SentenceTransformer(\"microsoft/mpnet-base\")\n                teacher_model = SentenceTransformer(\"all-mpnet-base-v2\")\n                train_dataset = Dataset.from_dict({\n                    \"query\": [\"It's nice weather outside today.\", \"He drove to work.\"],\n                    \"passage1\": [\"It's so sunny.\", \"He took the car to work.\"],\n                    \"passage2\": [\"It's very sunny.\", \"She walked to the store.\"],\n                })\n\n                def compute_labels(batch):\n                    emb_queries = teacher_model.encode(batch[\"query\"])\n                    emb_passages1 = teacher_model.encode(batch[\"passage1\"])\n                    emb_passages2 = teacher_model.encode(batch[\"passage2\"])\n                    return {\n                        \"label\": teacher_model.similarity_pairwise(emb_queries, emb_passages1) - teacher_model.similarity_pairwise(emb_queries, emb_passages2)\n                    }\n\n                train_dataset = train_dataset.map(compute_labels, batched=True)\n                # In this example, the labels become -0.036 and 0.68, respectively\n                loss = losses.MarginMSELoss(student_model)\n\n                trainer = SentenceTransformerTrainer(\n                    model=student_model,\n                    train_dataset=train_dataset,\n                    loss=loss,\n                )\n                trainer.train()\n        \"\"\"\n        super().__init__()\n        self.model = model\n        self.similarity_fct = similarity_fct\n        self.loss_fct = nn.MSELoss()\n\n    def forward(self, sentence_features: Iterable[dict[str, Tensor]], labels: Tensor) -> Tensor:\n        # sentence_features: query, positive passage, negative passage\n        reps = [self.model(sentence_feature)[\"sentence_embedding\"] for sentence_feature in sentence_features]\n        embeddings_query = reps[0]\n        embeddings_pos = reps[1]\n        embeddings_neg = reps[2]\n\n        scores_pos = self.similarity_fct(embeddings_query, embeddings_pos)\n        scores_neg = self.similarity_fct(embeddings_query, embeddings_neg)\n        margin_pred = scores_pos - scores_neg\n        #print(margin_pred.shape)\n        #print(margin_pred)\n        margin_pred= F.normalize(margin_pred, p=1.0, dim = 0)\n        labels= F.normalize(labels, p=1.0, dim = 0)\n        return self.loss_fct(margin_pred, labels)\n\n    @property\n    def citation(self) -> str:\n        return \"\"\"\n@misc{hofstätter2021improving,\n    title={Improving Efficient Neural Ranking Models with Cross-Architecture Knowledge Distillation},\n    author={Sebastian Hofstätter and Sophia Althammer and Michael Schröder and Mete Sertkan and Allan Hanbury},\n    year={2021},\n    eprint={2010.02666},\n    archivePrefix={arXiv},\n    primaryClass={cs.IR}\n}\n\"\"\"\nloss = MarginMSELoss(model)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import TrainerCallback\nclass MyCallback(TrainerCallback):\n    \"A callback that prints a message at the beginning of training\"\n\n    def on_save(self, args, state, control, **kwargs):\n        \"\"\"\n        Event called after a checkpoint save.\n        \"\"\"\n        print(\"save checkpoint\")\n        print(state.global_step)\n        if state.global_step ==-1 : control.should_training_stop=True","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 6. Create the trainer & start training\ntrainer = SentenceTransformerTrainer(    \n    model=model,    \n    args=training_args,    \n    train_dataset=train_dataset[\"train0\"],    \n    eval_dataset= train_dataset[\"test\"],    \n    loss=loss,    \n    evaluator=RerankingEvaluator(dev_samples),    \n    tokenizer=tokenizer,    \n    callbacks = [EarlyStoppingCallback(early_stopping_patience=10), MyCallback]    \n    #evaluator=triplet_evaluator,\n    )\n#train_result = trainer.train()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer.train()\n#trainer.train(resume_from_checkpoint = True)\n#trainer.save_model()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# uncomment to push to yrour huggingface hub\n\"\"\"\nimport huggingface_hub \nhf = huggingface_hub.HfFolder()\naccess_token = \"your access token\"\nhf.save_token(access_token)\nmodel.push_to_hub(\"hatemestinbejaia/\"+checkpoint)\ntokenizer.push_to_hub(\"hatemestinbejaia/\"+checkpoint)\n\"\"\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"testmodel = SentenceTransformer(\"hatemestinbejaia/\"+checkpoint)\ndev_evaluator=RerankingEvaluator(dev_samples)\nresult= dev_evaluator(testmodel)\nresult","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}